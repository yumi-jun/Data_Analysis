{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yumi-jun/Data_Analysis/blob/main/artificial_neural_network_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP6JLo1tGNBg"
      },
      "source": [
        "# Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWZyYmS_UE_L"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "XDI-5k4qPBVh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#텐서 플로우 버\n",
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dph5hDK6PRLC",
        "outputId": "cede5ec4-5c4c-4a0a-f42f-71e13bc6294c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.15.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E0Q3aoKUCRX"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKWAkFVGUU0Z"
      },
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('Churn_Modelling.csv')\n",
        "# 이름과 번호를 제외한 데이터\n",
        "X = dataset.iloc[:, 3:-1].values\n",
        "#이탈률\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "ichI_VMRQxh5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTpp5QHORus-",
        "outputId": "0dd0f0e7-b70d-486e-8ec9-928b0eb5f10d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[619 'France' 'Female' ... 1 1 101348.88]\n",
            " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
            " [502 'France' 'Female' ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 'Female' ... 0 1 42085.58]\n",
            " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
            " [792 'France' 'Female' ... 1 0 38190.78]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y69ruOijRu4L",
        "outputId": "9e6e8df2-414b-4a89-8cdb-d88b11dcd856"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 ... 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6bQ0UgSU-NJ"
      },
      "source": [
        "### Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le5MJreAbW52"
      },
      "source": [
        "Label Encoding the \"Gender\" column"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LabelEncoder 을 sklearn.preprocessing 모듈에서 가져오고,\n",
        "# 범주형 데이터를 라벨 데이터 로 변환한다.\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "# 성별 데이터 female, male 을 0,1 로 변환\n",
        "X[:, 2] = le.fit_transform(X[:, 2])"
      ],
      "metadata": {
        "id": "RsDzhgosSLD7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUccq8qIazXg",
        "outputId": "84c2b88f-d83b-4620-8c96-3ad0b6586435"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[619 'France' 0 ... 1 1 101348.88]\n",
            " [608 'Spain' 0 ... 0 1 112542.58]\n",
            " [502 'France' 0 ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 0 ... 0 1 42085.58]\n",
            " [772 'Germany' 1 ... 1 0 92888.52]\n",
            " [792 'France' 0 ... 1 0 38190.78]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUxGZezpbMcb"
      },
      "source": [
        "One Hot Encoding the \"Geography\" column"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"지역\" 열을 원-핫 코딩을 해보자 !\n",
        "\n",
        "원핫 코딩이란?\n",
        "범주형 데이터를 이진 벡터로 변환하는"
      ],
      "metadata": {
        "id": "wgtQ93m_Uwvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# 적용하고 싶은 열 -> 두번째 열, 인덱스 1번째\n",
        "# OneHotEncoder 가 해당 열을 인코딩하면서 새로운 열들을 추가하고,\n",
        "# 인코딩 된 열들을 가장 앞으로 배치한다.\n",
        "# ColumnTransformer 는 변환된 열을 기본적으로 앞쪽에 위치시킨다.\n",
        "\n",
        "#프랑스는 1,0,0, 독일 0,0,1 이렇게 인코딩 된다!\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))\n",
        "print(X)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ThLy7qQSLSQ",
        "outputId": "517c2cd8-5ec0-40fc-fe0a-d09b41600d84"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 ... 1 1 101348.88]\n",
            " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
            " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
            " ...\n",
            " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
            " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
            " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHol938cW8zd"
      },
      "source": [
        "### Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터를 무작위로 학습 세트와 테스트 세트로 나눈다.\n",
        "from sklearn.model_selection import train_test_split\n",
        "# 학습 데이터는 80, 훈련 데이터는 20%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "HKW9wiSGu8_f"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 분할된 데이터의 크기 출력\n",
        "print(X.shape)\n",
        "print(\"X_train 크기:\", X_train.shape)\n",
        "print(\"X_test 크기:\", X_test.shape)\n",
        "print(\"y_train 크기:\", y_train.shape)\n",
        "print(\"y_test 크기:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j08opQJDvv9r",
        "outputId": "7d5b8b19-82e7-40cc-a22d-4e9a30a3f37f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 12)\n",
            "X_train 크기: (8000, 12)\n",
            "X_test 크기: (2000, 12)\n",
            "y_train 크기: (8000,)\n",
            "y_test 크기: (2000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE_FcHyfV3TQ"
      },
      "source": [
        "### Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터픞 표준화하는 과정\n",
        "# 데이터의 평균을 0, 표준편차를 1로\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "# 데이터의 평균과 표준편차를 계산, 학습용데이터에 대해 사용\n",
        "X_train = sc.fit_transform(X_train)\n",
        "# 이미 계산된 평균과 표준편차를 사용해 데이터를 변환\n",
        "# 테스트 데이터에 대해 사용한다.\n",
        "X_test = sc.transform(X_test)\n"
      ],
      "metadata": {
        "id": "1hENgtxLvB4l"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zfEzkRVXIwF"
      },
      "source": [
        "## Part 2 - Building the ANN\n",
        "## 인공신경망을 만들어보자 - 구조 정의"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvdeScabXtlB"
      },
      "source": [
        "### Initializing the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Adding the second hidden layer\n",
        "\n"
      ],
      "metadata": {
        "id": "zi7QldJZalSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "H8hw6gDMYh8o"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BELWAc_8YJze"
      },
      "source": [
        "### Adding the second hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ann.add : 텐서 플로우를 사용하여, 인공 신경망의 레이어를 추가하는 것\n",
        "# tf.keras.layers.Dense 밀집 레이어를 의미, 레이어의 뉴런 노드 수, 활성화 함수 relu : ReLu 활성화 함수\n",
        "# 입력이 0보다 작으면, 0출력, 0보다 크면 입력 값을 그대로 출력\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n"
      ],
      "metadata": {
        "id": "brckDNUTYtVO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyNEe6RXYcU4"
      },
      "source": [
        "### Adding the output layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 마지막 출력층 값 ->출력증 값이 이진 변수로 1로 변경\n",
        "# 만약 출력층 값이, abc 와 같이 이진 변수가 아닐 경우에는 1 이 아닌 3 으로 ,,\n",
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "oFcfT5YHa1h3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT4u2S1_Y4WG"
      },
      "source": [
        "## Part 3 - Training the ANN\n",
        "학습 준"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kWz6e4Z0uAgM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GWlJChhY_ZI"
      },
      "source": [
        "### Compiling the ANN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델이 학습할 때 , 가중치를 조정하는 방법 optimizer , adam 은 최적화 알고리즘 : 학습을 더 빠르고 효율적으로\n",
        "# loss: 모델이 예측한 값과 실제 값의 차이를 계산, binary_crossentropy : 이진 분류 문제에 적합한 손실 함\n",
        "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
      ],
      "metadata": {
        "id": "XNQmOPQYcBlX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QR_G5u7ZLSM"
      },
      "source": [
        "### Training the ANN on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습할 입력데이터, 학습용 정답 레이블, 모델이 한 번에 학습할 데이터의 샘플 수 :32 , 32개의 샘플을 한번에 처리\n",
        "# 에포크 수 : 전체 데이터 셋에 대해 학습을 반복하는 횟\n",
        "ann.fit(X_train ,y_train, batch_size = 32, epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YS7oAGwtgvK",
        "outputId": "112bf5e5-269a-4867-c093-1bdef036b093"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 3s 5ms/step - loss: 0.5556 - accuracy: 0.7381\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.4721 - accuracy: 0.7959\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4464 - accuracy: 0.7970\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4302 - accuracy: 0.8065\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.4170 - accuracy: 0.8145\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.4039 - accuracy: 0.8265\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.3903 - accuracy: 0.8339\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3786 - accuracy: 0.8429\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3702 - accuracy: 0.8460\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3634 - accuracy: 0.8487\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3591 - accuracy: 0.8512\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3556 - accuracy: 0.8522\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8541\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3504 - accuracy: 0.8544\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3488 - accuracy: 0.8571\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3468 - accuracy: 0.8561\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3458 - accuracy: 0.8547\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3443 - accuracy: 0.8580\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3432 - accuracy: 0.8585\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.8591\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3416 - accuracy: 0.8602\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3407 - accuracy: 0.8606\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3398 - accuracy: 0.8612\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3395 - accuracy: 0.8610\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3388 - accuracy: 0.8615\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3381 - accuracy: 0.8609\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3379 - accuracy: 0.8601\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3377 - accuracy: 0.8612\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3370 - accuracy: 0.8614\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3369 - accuracy: 0.8608\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3364 - accuracy: 0.8600\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3364 - accuracy: 0.8591\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3357 - accuracy: 0.8616\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3354 - accuracy: 0.8611\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3358 - accuracy: 0.8608\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3352 - accuracy: 0.8612\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3351 - accuracy: 0.8616\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3351 - accuracy: 0.8609\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3347 - accuracy: 0.8608\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3346 - accuracy: 0.8615\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3348 - accuracy: 0.8618\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3345 - accuracy: 0.8618\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3344 - accuracy: 0.8620\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3343 - accuracy: 0.8627\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3339 - accuracy: 0.8619\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3341 - accuracy: 0.8608\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3338 - accuracy: 0.8611\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3338 - accuracy: 0.8627\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3338 - accuracy: 0.8599\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3336 - accuracy: 0.8616\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3334 - accuracy: 0.8608\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3336 - accuracy: 0.8615\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3333 - accuracy: 0.8614\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3332 - accuracy: 0.8633\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3331 - accuracy: 0.8619\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8616\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3327 - accuracy: 0.8616\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3325 - accuracy: 0.8621\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3325 - accuracy: 0.8612\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3326 - accuracy: 0.8625\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3327 - accuracy: 0.8611\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3322 - accuracy: 0.8611\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3325 - accuracy: 0.8618\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3323 - accuracy: 0.8615\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8626\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3316 - accuracy: 0.8615\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8624\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3318 - accuracy: 0.8630\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8619\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3317 - accuracy: 0.8637\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3319 - accuracy: 0.8624\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3316 - accuracy: 0.8626\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3317 - accuracy: 0.8629\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3313 - accuracy: 0.8624\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3314 - accuracy: 0.8604\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3315 - accuracy: 0.8618\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3312 - accuracy: 0.8624\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3309 - accuracy: 0.8616\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3313 - accuracy: 0.8626\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3308 - accuracy: 0.8626\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3308 - accuracy: 0.8624\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3309 - accuracy: 0.8636\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3309 - accuracy: 0.8622\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3309 - accuracy: 0.8643\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3306 - accuracy: 0.8629\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3308 - accuracy: 0.8636\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3311 - accuracy: 0.8644\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3309 - accuracy: 0.8630\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3305 - accuracy: 0.8658\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3305 - accuracy: 0.8634\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3302 - accuracy: 0.8651\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3308 - accuracy: 0.8626\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3305 - accuracy: 0.8637\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3303 - accuracy: 0.8622\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3304 - accuracy: 0.8643\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3304 - accuracy: 0.8659\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3304 - accuracy: 0.8648\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3303 - accuracy: 0.8644\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3305 - accuracy: 0.8646\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3303 - accuracy: 0.8635\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7effd298c340>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJj5k2MxZga3"
      },
      "source": [
        "## Part 4 - Making the predictions and evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84QFoqGYeXHL"
      },
      "source": [
        "### Predicting the result of a single observation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGRo3eacgDdC"
      },
      "source": [
        "**Homework**\n",
        "\n",
        "Use our ANN model to predict if the customer with the following informations will leave the bank:\n",
        "\n",
        "Geography: France\n",
        "\n",
        "Credit Score: 600\n",
        "\n",
        "Gender: Male\n",
        "\n",
        "Age: 40 years old\n",
        "\n",
        "Tenure: 3 years\n",
        "\n",
        "Balance: \\$ 60000\n",
        "\n",
        "Number of Products: 2\n",
        "\n",
        "Does this customer have a credit card? Yes\n",
        "\n",
        "Is this customer an Active Member: Yes\n",
        "\n",
        "Estimated Salary: \\$ 50000\n",
        "\n",
        "So, should we say goodbye to that customer?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhU1LTgPg-kH"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측 메소드의 입력값은 2d 배열이여야 한다.\n",
        "# sc.transform : 정규화하는 과정\n",
        "# 마지막 ann 을 만들때의 함수가 시그노이드 함수 -> 확률 로 값을 출력해\n",
        "# 0.5 확률보다 아래니까 떠날 확률은 낮다!!!\n",
        "print(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQbgdstLxqyr",
        "outputId": "081e463f-c4e5-4bee-b77b-e565872dd5cc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "[[0.3896976]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGjx94g2n7OV"
      },
      "source": [
        "Therefore, our ANN model predicts that this customer stays in the bank!\n",
        "\n",
        "**Important note 1:** Notice that the values of the features were all input in a double pair of square brackets. That's because the \"predict\" method always expects a 2D array as the format of its inputs. And putting our values into a double pair of square brackets makes the input exactly a 2D array.\n",
        "\n",
        "**Important note 2:** Notice also that the \"France\" country was not input as a string in the last column but as \"1, 0, 0\" in the first three columns. That's because of course the predict method expects the one-hot-encoded values of the state, and as we see in the first row of the matrix of features X, \"France\" was encoded as \"1, 0, 0\". And be careful to include these values in the first three columns, because the dummy variables are always created in the first columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7yx47jPZt11"
      },
      "source": [
        "### Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터 x_text 에 대해 모델이 예측을 수행\n",
        "# y_pred 에 모델이 예측한 확률값을 담고 있다.\n",
        "y_pred = ann.predict(X_test)\n",
        "print(y_pred) # 각 행의 예측값들\n",
        "y_pred = (y_pred > 0.5) # 예측값을 0 과 1로 바꿈 이진화\n",
        "\n",
        "# y_pred 와 y_test 를 나란히 결합하여 비교\n",
        "# y_pred 는 방금 만든 딥러닝 모델로 예측한 값이고\n",
        "# y_test 는 이미 데이터에 주어진 실제 값.\n",
        "# reshape 로 각각의 열 벡터로 변환\n",
        "# np.concatenate 는 두 열 벡터를 옆으로 결합\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n",
        "# 1은 은행을 떠난 것, 0은 떠나지 않은"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBZVe1fo3H8q",
        "outputId": "74d3c9c5-6410-4265-dbe8-042bcf5c546a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 1ms/step\n",
            "[[0.28022423]\n",
            " [0.33390072]\n",
            " [0.17737262]\n",
            " ...\n",
            " [0.11820526]\n",
            " [0.17131951]\n",
            " [0.16235702]]\n",
            "[[0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " ...\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0oyfLWoaEGw"
      },
      "source": [
        "### Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XovVtnv55Odr",
        "outputId": "b9e19a6e-890f-446c-b53f-f3e83b7b2124"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1502   93]\n",
            " [ 188  217]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8595"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}